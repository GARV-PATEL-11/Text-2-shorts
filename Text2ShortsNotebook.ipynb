{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26f417c0-ca65-48a4-bc7f-e427b7089c0e",
   "metadata": {},
   "source": [
    "### **1. Configure Gemini API Access**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48269c85-19a9-4b69-b723-99b35fc43830",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = \"YourGeminiAPIKey\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac8ff74-33f5-47c2-925d-cba060332da2",
   "metadata": {},
   "source": [
    "### **2. Select Your Topic of Interest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4130afce-0c2b-4807-bf4f-a9c59fb59b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_INPUT = input(\"Please Provide The Topic Of Your Choice: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40723190-a146-4400-87be-cac4600626c0",
   "metadata": {},
   "source": [
    "### **3. Generate Custom Prompt for LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c497a51a-c065-4c37-bbdd-a4cc44a003b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the prompt builder function for generating enhanced conversational scripts\n",
    "from SRC.PromptBuilder import get_enhanced_conversational_script_prompt\n",
    "\n",
    "# Generate a conversational script prompt tailored for high-quality video generation.\n",
    "# This function enhances a given paragraph into a script with specific tone, style, and format requirements.\n",
    "\n",
    "PROMPT = get_enhanced_conversational_script_prompt(\n",
    "    \n",
    "    # The input paragraph to be transformed into a conversational script\n",
    "    paragraph=USER_INPUT,\n",
    "    \n",
    "    # Intended expertise level of the target audience: \n",
    "    # Options: \"beginner\", \"intermediate\", \"advanced\", or \"expert\"\n",
    "    audience_level=\"expert\",\n",
    "    \n",
    "    # Overall tone of the script. \n",
    "    # Options include: \"conversational\", \"explanatory\", \"narrative\", \"tutorial\", \"inspirational\", \"analytical\"\n",
    "    tone=\"analytical\",\n",
    "    \n",
    "    # Desired duration of the output script, in minutes\n",
    "    duration_minutes=2,\n",
    "    \n",
    "    # Whether to include elements that directly engage the viewer (e.g., questions, prompts)\n",
    "    include_engagement=True,\n",
    "    \n",
    "    # Degree of academic complexity or depth of explanation. \n",
    "    # Options: \"light\", \"moderate\", \"rigorous\", or \"scholarly\"\n",
    "    academic_rigor=\"scholarly\",\n",
    "    \n",
    "    # The type of content being produced. \n",
    "    # Options: \"educational\", \"entertainment\", \"professional\", \"academic\", \"tutorial\"\n",
    "    content_type=\"professional\",\n",
    "    \n",
    "    # Whether to include descriptions or references to visual elements (e.g., diagrams, animations)\n",
    "    visual_elements=True,\n",
    "    \n",
    "    # Whether to include interactive elements (e.g., pauses for user input, quizzes, code exercises)\n",
    "    interactive_elements=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2f559-5d3b-4c43-9534-fb6f4f76e54f",
   "metadata": {},
   "source": [
    "### **4. Script Generation via Language Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5d70bb1-87c2-43d7-b961-1a5f5e01cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai  # Import the Google Generative AI client library\n",
    "\n",
    "# Specify the model to use: Gemini 1.5 Flash (latest fast inference model)\n",
    "MODEL_NAME = \"models/gemini-1.5-flash-latest\"\n",
    "\n",
    "# Authenticate using your Gemini API key\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Initialize the generative model with the specified configuration\n",
    "model = genai.GenerativeModel(model_name=MODEL_NAME)\n",
    "\n",
    "# Attempt to generate content using the prompt\n",
    "try:\n",
    "    response = model.generate_content(PROMPT)  # Generate content based on the structured prompt\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)  # Print the error if content generation fails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da15b9f-0ac4-4a0f-bd96-0bc7542c0e0c",
   "metadata": {},
   "source": [
    "### **5. Review Generated Script Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af12c576-5647-4bc1-96ae-525197176124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**(0:00-0:15) [MAGNETIC HOOK]**\\n\\nImagine a world where machines learn not through explicit programming, but through the absorption and interpretation of vast datasets.  That world is here, powered by deep learning.  This isn\\'t just another algorithm; it\\'s a paradigm shift. [VISUAL CUE: Dramatic visual of interconnected nodes representing a neural network].  This changes everything.\\n\\n**(0:15-0:30) [CONTEXT FOUNDATION]**\\n\\nBefore we dive in, let\\'s establish a common understanding. Deep learning is a subset of machine learning, itself a branch of artificial intelligence.  It leverages artificial neural networks, inspired by the structure and function of the human brain, [VISUAL CUE: Simple brain diagram transitioning to a neural network visualization].  Think of it as a sophisticated pattern-recognition engine.\\n\\n**(0:30-1:15) [CORE KNOWLEDGE TRANSFER]**\\n\\n**Segment 1:**  At its core, deep learning uses multiple layers of interconnected nodes to extract increasingly complex features from raw data. [VISUAL CUE: Animated layers of a neural network highlighting feature extraction].  This hierarchical processing allows for the identification of intricate patterns humans might miss. [PAUSE FOR REFLECTION]\\n\\n**Segment 2:**  Backpropagation, an essential algorithm, adjusts the network\\'s weights based on errors, iteratively refining its accuracy. [VISUAL CUE: Animation demonstrating backpropagation, color-coding weight adjustments].  This iterative refinement is key to its power.  [VIEWER CHALLENGE: Consider the computational demands of such iterative processes].\\n\\n**Segment 3:**  Applications range from image recognition and natural language processing to drug discovery and financial modeling.  [VISUAL CUE: Rapid montage showcasing diverse applications]. [COMMENT PROMPT: What unexpected applications of deep learning excite you?]\\n\\n**(1:15-1:30) [PRACTICAL MASTERY]**\\n\\nConsider image classification.  Traditional methods rely on hand-crafted features.  Deep learning, however, learns these features automatically, leading to significantly improved accuracy. [VISUAL CUE: Side-by-side comparison of traditional vs. deep learning image classification]. [RESOURCE LINK: Recent research paper on image classification]\\n\\n**(1:30-1:45) [CRITICAL THINKING DEVELOPMENT]**\\n\\nDespite its power, deep learning isn\\'t without limitations.  Data bias can lead to unfair or discriminatory outcomes.  [VISUAL CUE:  Graph illustrating bias in data].  Furthermore, the \"black box\" nature of deep learning makes interpretability challenging. [POLL/QUIZ: What are the ethical considerations of deep learning?]\\n\\n**(1:45-2:00) [SYNTHESIS & TRANSFORMATION]**\\n\\nDeep learning represents a profound advancement, but ethical considerations and the need for transparency are paramount. [VISUAL CUE:  Image symbolizing responsible AI development].  [PAUSE FOR REFLECTION]. The future of deep learning is not predetermined; it\\'s shaped by our collective choices.  What role will you play?\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f831fe-3d73-4957-b6b3-911060f8c84d",
   "metadata": {},
   "source": [
    "### **6. Prepare Audio Narration Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5dd507a-fc92-406b-a76c-2d8c0094d02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéôÔ∏è AUDIO NARRATION SCRIPT:\n",
      "==================================================\n",
      "Imagine a world where machines learn not through explicit programming, but through the absorption and interpretation of vast datasets. That world is here, powered by deep learning. This isn't just another algorithm; it's a paradigm shift. . This changes everything. Before we dive in, let's establish a common understanding. Deep learning is a subset of machine learning, itself a branch of artificial intelligence. It leverages artificial neural networks, inspired by the structure and function of the human brain, . Think of it as a sophisticated pattern-recognition engine. Segment 1: At its core, deep learning uses multiple layers of interconnected nodes to extract increasingly complex features from raw data. . This hierarchical processing allows for the identification of intricate patterns humans might miss. Segment 2: Backpropagation, an essential algorithm, adjusts the network's weights based on errors, iteratively refining its accuracy. . This iterative refinement is key to its power. . Segment 3: Applications range from image recognition and natural language processing to drug discovery and financial modeling. . Consider image classification. Traditional methods rely on hand-crafted features. Deep learning, however, learns these features automatically, leading to significantly improved accuracy. . Despite its power, deep learning isn't without limitations. Data bias can lead to unfair or discriminatory outcomes. . Furthermore, the \"black box\" nature of deep learning makes interpretability challenging. Deep learning represents a profound advancement, but ethical considerations and the need for transparency are paramount. . . The future of deep learning is not predetermined; it's shaped by our collective choices. What role will you play?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from SRC.ScriptCleaner import video_script_to_audio_text\n",
    "\n",
    "# === Step 1: Extract audio narration from full script text ===\n",
    "audio_script = video_script_to_audio_text(response.text)\n",
    "print(\"üéôÔ∏è AUDIO NARRATION SCRIPT:\\n\" + \"=\" * 50)\n",
    "print(audio_script)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de30cfbd-f776-4366-8b31-8570882fd2c3",
   "metadata": {},
   "source": [
    "### **7. Prepare Visual Animation Script** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc34629d-99f5-4b8c-bf98-d77b0694ff5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ STRUCTURED VIDEO SCRIPT SEGMENTS:\n",
      "==================================================\n",
      "\n",
      "üß© Section: magnetic_hook\n",
      "Title: Magnetic Hook\n",
      "Start Time: 0:00\n",
      "End Time: 0:15\n",
      "Duration (s): 15\n",
      "Word Count: 40\n",
      "Estimated Tokens: 54\n",
      "Audio Script:\n",
      "Imagine a world where machines learn not through explicit programming, but through the absorption and interpretation of vast datasets. That world is here, powered by deep learning. This isn't just another algorithm; it's a paradigm shift. . This changes everything.\n",
      "\n",
      "üîç Visual Elements:\n",
      "- visual_cue: Dramatic visual of interconnected nodes representing a neural network\n",
      "------------------------------------------------------------\n",
      "\n",
      "üß© Section: context_foundation\n",
      "Title: Context Foundation\n",
      "Start Time: 0:00\n",
      "End Time: 0:15\n",
      "Duration (s): 15\n",
      "Word Count: 47\n",
      "Estimated Tokens: 63\n",
      "Audio Script:\n",
      "Before we dive in, let's establish a common understanding. Deep learning is a subset of machine learning, itself a branch of artificial intelligence. It leverages artificial neural networks, inspired by the structure and function of the human brain, . Think of it as a sophisticated pattern-recognition engine.\n",
      "\n",
      "üîç Visual Elements:\n",
      "- visual_cue: Simple brain diagram transitioning to a neural network visualization\n",
      "------------------------------------------------------------\n",
      "\n",
      "üß© Section: core_knowledge_transfer\n",
      "Title: Core Knowledge Transfer\n",
      "Start Time: 0:00\n",
      "End Time: 0:15\n",
      "Duration (s): 15\n",
      "Word Count: 0\n",
      "Estimated Tokens: 0\n",
      "Audio Script:\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "üß© Section: practical_mastery\n",
      "Title: Practical Mastery\n",
      "Start Time: 0:00\n",
      "End Time: 0:15\n",
      "Duration (s): 15\n",
      "Word Count: 22\n",
      "Estimated Tokens: 29\n",
      "Audio Script:\n",
      "Consider image classification. Traditional methods rely on hand-crafted features. Deep learning, however, learns these features automatically, leading to significantly improved accuracy. .\n",
      "\n",
      "üîç Visual Elements:\n",
      "- visual_cue: Side-by-side comparison of traditional vs. deep learning image classification\n",
      "\n",
      "üéÆ Interactive Elements:\n",
      "- resource_link: Recent research paper on image classification\n",
      "------------------------------------------------------------\n",
      "\n",
      "üß© Section: critical_thinking_development\n",
      "Title: Critical Thinking Development\n",
      "Start Time: 0:00\n",
      "End Time: 0:15\n",
      "Duration (s): 15\n",
      "Word Count: 29\n",
      "Estimated Tokens: 39\n",
      "Audio Script:\n",
      "Despite its power, deep learning isn't without limitations. Data bias can lead to unfair or discriminatory outcomes. . Furthermore, the \"black box\" nature of deep learning makes interpretability challenging.\n",
      "\n",
      "üîç Visual Elements:\n",
      "- visual_cue: Graph illustrating bias in data\n",
      "\n",
      "üéÆ Interactive Elements:\n",
      "- poll_quiz: What are the ethical considerations of deep learning?\n",
      "------------------------------------------------------------\n",
      "\n",
      "üß© Section: synthesis_transformation\n",
      "Title: Synthesis Transformation\n",
      "Start Time: 0:00\n",
      "End Time: 0:15\n",
      "Duration (s): 15\n",
      "Word Count: 37\n",
      "Estimated Tokens: 49\n",
      "Audio Script:\n",
      "Deep learning represents a profound advancement, but ethical considerations and the need for transparency are paramount. . . The future of deep learning is not predetermined; it's shaped by our collective choices. What role will you play?\n",
      "\n",
      "üîç Visual Elements:\n",
      "- visual_cue: Image symbolizing responsible AI development\n",
      "\n",
      "üéÆ Interactive Elements:\n",
      "- pause_reflection: [PAUSE FOR REFLECTION]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import the function to tokenize the video script into structured segments\n",
    "from SRC.ScriptCleaner import tokenize_video_script\n",
    "\n",
    "# Tokenize the response text into a dictionary of script segments\n",
    "video_script_segments = tokenize_video_script(response.text)\n",
    "\n",
    "# Print each segment with relevant metadata and content\n",
    "print(\"üé¨ STRUCTURED VIDEO SCRIPT SEGMENTS:\\n\" + \"=\" * 50)\n",
    "\n",
    "for key, segment in video_script_segments.items():\n",
    "    print(f\"\\nüß© Section: {key}\")\n",
    "    print(f\"Title: {segment.title}\")\n",
    "    print(f\"Start Time: {segment.time_start}\")\n",
    "    print(f\"End Time: {segment.time_end}\")\n",
    "    print(f\"Duration (s): {segment.duration_seconds}\")\n",
    "    print(f\"Word Count: {segment.word_count}\")\n",
    "    print(f\"Estimated Tokens: {segment.estimated_tokens}\")\n",
    "    print(\"Audio Script:\")\n",
    "    print(segment.audio_script)\n",
    "\n",
    "    # Print visual elements if available\n",
    "    if segment.visual_elements:\n",
    "        print(\"\\nüîç Visual Elements:\")\n",
    "        for visual in segment.visual_elements:\n",
    "            print(f\"- {visual.description}: {visual.content}\")\n",
    "\n",
    "    # Print interactive elements if available\n",
    "    if segment.interactive_elements:\n",
    "        print(\"\\nüéÆ Interactive Elements:\")\n",
    "        for inter in segment.interactive_elements:\n",
    "            print(f\"- {inter.description}: {inter.content}\")\n",
    "\n",
    "    # Print engagement elements if available\n",
    "    if segment.engagement_elements:\n",
    "        print(\"\\nüí¨ Engagement Elements:\")\n",
    "        for engage in segment.engagement_elements:\n",
    "            print(f\"- {engage.description}: {engage.content}\")\n",
    "\n",
    "    # Print structural elements if available\n",
    "    if segment.structural_elements:\n",
    "        print(\"\\nüèóÔ∏è Structural Elements:\")\n",
    "        for struct in segment.structural_elements:\n",
    "            print(f\"- {struct.description}: {struct.content}\")\n",
    "\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44b114e-a147-4bae-a152-608f3960d3ce",
   "metadata": {},
   "source": [
    "### **8. Convert Narration Script to Audio** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "390cd290-7d96-43f4-b15b-e50876df09bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved audio to output.mp3\n"
     ]
    }
   ],
   "source": [
    "# Import the Amazon Polly TTS wrapper function\n",
    "from SRC.AmazonPollyTTS import polly_speak_text\n",
    "\n",
    "# ‚ö†Ô∏è Caution:\n",
    "# This function uses Amazon Polly, which may incur AWS charges based on usage.\n",
    "# Ensure your AWS credentials are correctly configured and you stay within the free tier if applicable.\n",
    "# Avoid excessive or automated requests unless monitored, as it could lead to unexpected billing.\n",
    "# Refer to: https://aws.amazon.com/polly/pricing/ for cost details.\n",
    "\n",
    "# Convert the provided audio script to speech and play it using Amazon Polly\n",
    "polly_speak_text(audio_script)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d154e0-66cb-4b3e-a286-b604ae05ca19",
   "metadata": {},
   "source": [
    "### **9 Video Generation - Under Development**\n",
    "\n",
    "*The final phase of the workflow, which involves:*\n",
    "\n",
    "- *Animation generation*  \n",
    "- *Integration of audio with animation*  \n",
    "- *Rendering the final short video (approximately 2 minutes)*\n",
    "\n",
    "*is currently under active development.*\n",
    "\n",
    "*This section is not yet complete, and the full video output functionality is still being implemented.*\n",
    "\n",
    "*Please review the existing stages of the pipeline. Contributions are welcome, especially if you have expertise in animation, video rendering, or related areas.*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
